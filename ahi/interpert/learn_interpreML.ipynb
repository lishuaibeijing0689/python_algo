{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run benchmark script, you will need to install XGBoost \n",
    "# (pip install XGBoost)\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_breast_data():\n",
    "    breast = load_breast_cancer()\n",
    "    feature_names = list(breast.feature_names)\n",
    "    X, y = pd.DataFrame(breast.data, columns=feature_names), breast.target\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "        },\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_adult_data():\n",
    "    df = pd.read_csv(\"data/adult.data\",header=None)\n",
    "    df.columns = [\n",
    "        \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "    ]\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_heart_data():\n",
    "    # https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "    df = pd.read_csv('data/heart.csv')\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_credit_data():\n",
    "    # https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "    df = pd.read_csv('data/creditcard.csv')\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_telco_churn_data():\n",
    "    # https://www.kaggle.com/blastchar/telco-customer-churn/downloads/WA_Fn-UseC_-Telco-Customer-Churn.csv/1\n",
    "    df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    train_cols = df.columns[1:-1] # First column is an ID\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label] # 'Yes, No'\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_n(x):\n",
    "    return \"{0:.3f}\".format(x)\n",
    "\n",
    "\n",
    "def process_model(clf, name, X, y, n_splits=3):\n",
    "    # Evaluate model\n",
    "    ss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=1337)\n",
    "    scores = cross_validate(\n",
    "        clf, X, y, scoring='roc_auc', cv=ss,\n",
    "        n_jobs=None, return_estimator=True\n",
    "    )\n",
    "\n",
    "    record = dict()\n",
    "    record['model_name'] = name\n",
    "    record['fit_time_mean'] = format_n(np.mean(scores['fit_time']))\n",
    "    record['fit_time_std'] = format_n(np.std(scores['fit_time']))\n",
    "    record['test_score_mean'] = format_n(np.mean(scores['test_score']))\n",
    "    record['test_score_std'] = format_n(np.std(scores['test_score']))\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_models(dataset_name, X, y, ct=None, n_splits=3, random_state=1337):\n",
    "    if ct is None:\n",
    "        is_cat = np.array([dt.kind == 'O' for dt in X.dtypes])\n",
    "        cat_cols = X.columns.values[is_cat]\n",
    "        num_cols = X.columns.values[~is_cat]\n",
    "\n",
    "        cat_ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                                             handle_unknown='ignore'))\n",
    "\n",
    "        cat_pipe = Pipeline([cat_ohe_step])\n",
    "        num_pipe = Pipeline([('identity', FunctionTransformer())])\n",
    "        transformers = [\n",
    "            ('cat', cat_pipe, cat_cols),\n",
    "            ('num', num_pipe, num_cols)\n",
    "        ]\n",
    "        ct = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    summary_record = {}\n",
    "    summary_record['dataset_name'] = dataset_name\n",
    "    print()\n",
    "    print('-' * 78)\n",
    "    print(dataset_name)\n",
    "    print('-' * 78)\n",
    "    print(summary_record)\n",
    "    print()\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('std', StandardScaler()),\n",
    "        ('linear-sgd', SGDClassifier(random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'linear-sgd', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('std', StandardScaler()),\n",
    "        ('lr', LogisticRegression(random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'lr', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        # n_estimators updated from 10 to 100 due to sci-kit defaults changing in future versions\n",
    "        ('rf-100', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'rf-100', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('xgb', XGBClassifier(random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'xgb', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('lgb', lgb.LGBMClassifier(boosting_type=\"gbdt\", num_leaves=16, reg_alpha=0, reg_lambda=1,\n",
    "                             max_depth=-1, n_estimators=2000, objective='binary', subsample=0.8,\n",
    "                             colsample_bytree=0.8, subsample_freq=1,learning_rate=0.02, \n",
    "                             random_state=random_state, metric=\"auc\",n_jobs=-1)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'lgb', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "    \n",
    "\n",
    "    # No pipeline needed due to EBM handling string datatypes\n",
    "    ebm_main = ExplainableBoostingClassifier(n_jobs=-1, interactions=0, random_state=random_state)\n",
    "    record = process_model(ebm_main, 'ebm main', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "heart\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'heart'}\n",
      "\n",
      "{'model_name': 'linear-sgd', 'fit_time_mean': '0.005', 'fit_time_std': '0.001', 'test_score_mean': '0.885', 'test_score_std': '0.018'}\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.006', 'fit_time_std': '0.001', 'test_score_mean': '0.915', 'test_score_std': '0.034'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '0.120', 'fit_time_std': '0.021', 'test_score_mean': '0.908', 'test_score_std': '0.023'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '0.026', 'fit_time_std': '0.002', 'test_score_mean': '0.879', 'test_score_std': '0.017'}\n",
      "{'model_name': 'lgb', 'fit_time_mean': '0.434', 'fit_time_std': '0.175', 'test_score_mean': '0.869', 'test_score_std': '0.017'}\n",
      "{'model_name': 'ebm main', 'fit_time_mean': '0.996', 'fit_time_std': '0.479', 'test_score_mean': '0.925', 'test_score_std': '0.014'}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_splits = 5\n",
    "\n",
    "dataset = load_heart_data()\n",
    "result = benchmark_models('heart', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 13 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "dtypes: float64(1), int64(12)\n",
      "memory usage: 30.9 KB\n"
     ]
    }
   ],
   "source": [
    "dataset['full']['X'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "breast-cancer\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'breast-cancer'}\n",
      "\n",
      "{'model_name': 'linear-sgd', 'fit_time_mean': '0.007', 'fit_time_std': '0.004', 'test_score_mean': '0.993', 'test_score_std': '0.007'}\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.010', 'fit_time_std': '0.003', 'test_score_mean': '0.996', 'test_score_std': '0.005'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '0.173', 'fit_time_std': '0.011', 'test_score_mean': '0.991', 'test_score_std': '0.009'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '0.084', 'fit_time_std': '0.002', 'test_score_mean': '0.995', 'test_score_std': '0.005'}\n",
      "{'model_name': 'lgb', 'fit_time_mean': '0.387', 'fit_time_std': '0.014', 'test_score_mean': '0.994', 'test_score_std': '0.007'}\n",
      "{'model_name': 'ebm main', 'fit_time_mean': '1.892', 'fit_time_std': '0.800', 'test_score_mean': '0.995', 'test_score_std': '0.005'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_breast_data()\n",
    "result = benchmark_models('breast-cancer', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adult data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "adult\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'adult'}\n",
      "\n",
      "{'model_name': 'linear-sgd', 'fit_time_mean': '0.601', 'fit_time_std': '0.063', 'test_score_mean': '0.891', 'test_score_std': '0.005'}\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.302', 'fit_time_std': '0.010', 'test_score_mean': '0.907', 'test_score_std': '0.003'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '1.006', 'fit_time_std': '0.009', 'test_score_mean': '0.903', 'test_score_std': '0.002'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '8.373', 'fit_time_std': '0.018', 'test_score_mean': '0.922', 'test_score_std': '0.002'}\n",
      "{'model_name': 'lgb', 'fit_time_mean': '3.465', 'fit_time_std': '0.632', 'test_score_mean': '0.929', 'test_score_std': '0.002'}\n",
      "{'model_name': 'ebm main', 'fit_time_mean': '47.470', 'fit_time_std': '1.949', 'test_score_mean': '0.929', 'test_score_std': '0.002'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_adult_data()\n",
    "result = benchmark_models('adult', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## credit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_credit_data()\n",
    "['full']['X'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================fold:0===================================\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.999875\tvalid_1's auc: 0.982535\n",
      "[200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.981885\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's auc: 0.997912\tvalid_1's auc: 0.989163\n",
      "=====fold:0, best_score:0.9891628594475789, best_iteration:55\n",
      "===========================fold:1===================================\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.99986\tvalid_1's auc: 0.984373\n",
      "[200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.983368\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.983232\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's auc: 0.999966\tvalid_1's auc: 0.984852\n",
      "=====fold:1, best_score:0.9848524816957717, best_iteration:117\n",
      "===========================fold:2===================================\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.999838\tvalid_1's auc: 0.984401\n",
      "[200]\ttraining's auc: 0.999998\tvalid_1's auc: 0.984817\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.98376\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.999976\tvalid_1's auc: 0.987013\n",
      "=====fold:2, best_score:0.9870126444260767, best_iteration:136\n",
      "===========================fold:3===================================\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.999886\tvalid_1's auc: 0.987508\n",
      "[200]\ttraining's auc: 0.999999\tvalid_1's auc: 0.985182\n",
      "[300]\ttraining's auc: 1\tvalid_1's auc: 0.984926\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's auc: 0.999972\tvalid_1's auc: 0.987709\n",
      "=====fold:3, best_score:0.9877092704376829, best_iteration:130\n",
      "===========================fold:4===================================\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.999803\tvalid_1's auc: 0.984863\n",
      "[200]\ttraining's auc: 0.999998\tvalid_1's auc: 0.98378\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.999311\tvalid_1's auc: 0.985457\n",
      "=====fold:4, best_score:0.9854573487942915, best_iteration:86\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_x,train_y = dataset['full']['X'],dataset['full']['y']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "for fold,(train_idx, val_idx) in enumerate(skf.split(train_x, train_y)):\n",
    "#     for fold,(train_idx, val_idx) in enumerate(kf.split(train_x)):\n",
    "    print(f'===========================fold:{fold}===================================')\n",
    "    X_train, y_train, X_valid, y_valid = train_x.iloc[train_idx], train_y[train_idx], train_x.iloc[val_idx], train_y[val_idx]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(boosting_type=\"gbdt\", num_leaves=10, reg_alpha=0, reg_lambda=1,\n",
    "                             max_depth=-1, n_estimators=2000, objective='binary', subsample=0.8,\n",
    "                             colsample_bytree=0.8, subsample_freq=1,learning_rate=0.02, \n",
    "                             random_state=1000*fold+66, metric=\"None\",n_jobs=-1)\n",
    "    \n",
    "    clf = ExplainableBoostingClassifier(n_jobs=-1, interactions=0, random_state=random_state)\n",
    "    \n",
    "    clf.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_valid, y_valid)], eval_metric = ['auc'],\n",
    "            verbose=100, early_stopping_rounds=200)\n",
    "    \n",
    "    temp_score = clf.best_score_['valid_1']['auc']\n",
    "    print(f'=====fold:{fold}, best_score:{temp_score}, best_iteration:{clf.best_iteration_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_x,train_y = dataset['full']['X'],dataset['full']['y']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "for fold,(train_idx, val_idx) in enumerate(skf.split(train_x, train_y)):\n",
    "#     for fold,(train_idx, val_idx) in enumerate(kf.split(train_x)):\n",
    "    print(f'===========================fold:{fold}===================================')\n",
    "    X_train, y_train, X_valid, y_valid = train_x.iloc[train_idx], train_y[train_idx], train_x.iloc[val_idx], train_y[val_idx]\n",
    "\n",
    "    clf = ExplainableBoostingClassifier(n_jobs=-1, interactions=0, n_estimators=500, learning_rate=0.05)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_pred = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "    temp_score = roc_auc_score(y_valid, val_pred)\n",
    "    print(f'=====fold:{fold}, best_score:{temp_score}, best_iteration:{clf.best_iteration_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "credit-fraud\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'credit-fraud'}\n",
      "\n",
      "{'model_name': 'linear-sgd', 'fit_time_mean': '0.676', 'fit_time_std': '0.084', 'test_score_mean': '0.980', 'test_score_std': '0.007'}\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.882', 'fit_time_std': '0.075', 'test_score_mean': '0.974', 'test_score_std': '0.008'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '34.787', 'fit_time_std': '1.363', 'test_score_mean': '0.942', 'test_score_std': '0.016'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '45.166', 'fit_time_std': '0.739', 'test_score_mean': '0.979', 'test_score_std': '0.004'}\n",
      "{'model_name': 'lgb', 'fit_time_mean': '17.583', 'fit_time_std': '0.374', 'test_score_mean': '0.984', 'test_score_std': '0.005'}\n",
      "{'model_name': 'ebm main', 'fit_time_mean': '456.001', 'fit_time_std': '665.034', 'test_score_mean': '0.969', 'test_score_std': '0.007'}\n"
     ]
    }
   ],
   "source": [
    "result = benchmark_models('credit-fraud', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## telcom churn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "telco-churn\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'telco-churn'}\n",
      "\n",
      "{'model_name': 'linear-sgd', 'fit_time_mean': '2.236', 'fit_time_std': '0.213', 'test_score_mean': '0.798', 'test_score_std': '0.008'}\n",
      "{'model_name': 'lr', 'fit_time_mean': '25.970', 'fit_time_std': '2.931', 'test_score_mean': '0.804', 'test_score_std': '0.015'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '3.310', 'fit_time_std': '1.204', 'test_score_mean': '0.824', 'test_score_std': '0.002'}\n",
      "{'model_name': 'xgb', 'fit_time_mean': '140.873', 'fit_time_std': '0.970', 'test_score_mean': '0.850', 'test_score_std': '0.006'}\n",
      "{'model_name': 'ebm main', 'fit_time_mean': '11.451', 'fit_time_std': '1.413', 'test_score_mean': '0.851', 'test_score_std': '0.005'}\n",
      "{'model_name': 'ebm-interact', 'fit_time_mean': '5.363', 'fit_time_std': '0.854', 'test_score_mean': '0.851', 'test_score_std': '0.005'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_telco_churn_data()\n",
    "result = benchmark_models('telco-churn', dataset['full']['X'], dataset['full']['y'], n_splits=3)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [item for result in results for item in result]\n",
    "record_df = pd.DataFrame.from_records(records)[['dataset_name', 'model_name', 'test_score_mean', 'test_score_std']]\n",
    "record_df.to_csv('ebm-perf-classification-overnight.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
