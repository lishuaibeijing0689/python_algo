{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据统计\n",
    "def df_miss_rate(df):\n",
    "    \"\"\" 计算每一列的缺失值数量和比例 \"\"\"\n",
    "    ret = dict()\n",
    "    total = df.count()\n",
    "    for col in df.columns:\n",
    "        ret[col] = df.select(col).dropna().count()\n",
    "    col_misscnt = [(x[0], total-x[1], 1-1.0*x[1]/total) for x in ret.items()]\n",
    "    return pd.DataFrame(sorted(col_misscnt, key=lambda x: x[-1]), columns=['col', 'miss_cnt', 'miss_ratio'])\n",
    "\n",
    "def df_col_value_distinct_cnt(df):\n",
    "    \"\"\" 计算每列的取值数量 \"\"\"\n",
    "    ret = dict()\n",
    "    for col in df.columns:\n",
    "        ret[col] = df.select(col).distinct().count()\n",
    "    return pd.DataFrame(sorted(ret.items(), key=lambda x: x[1]), columns=['col', 'value_cnt'])\n",
    "\n",
    "def df_col_value_distribute(df, col, n=5):\n",
    "    \"\"\" 计算给定字段里每个字段的取值和事件数字典，每个字段只取事件数最多的前n个值 \"\"\"\n",
    "    return df.select(col).groupby(col).count().sort('count', ascending=False).limit(n).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 衍生函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from derive_package.ip import IPSeeker\n",
    "from derive_package.ua_parser import user_agent_parser\n",
    "\n",
    "def derive_ip_prefix(x, **kwargs):\n",
    "    \"\"\" 取ip前缀\"\"\"\n",
    "    len_list = kwargs.get('prefix', [20, 22, 24])\n",
    "    ret = dict()\n",
    "    try:\n",
    "        if len(x) < 5:\n",
    "            return dict([('prefix_%d' % x, '') for x in len_list])\n",
    "        for length in len_list:\n",
    "            mask = (1 << 32) - (1 << 32 - length)\n",
    "            mask_l = [mask >> 24, (mask >> 16) & 255, (mask >> 8) & 255, mask & 255]\n",
    "            ret.update({'prefix_%d' % length: '.'.join(map(lambda x: str(x[0] & x[1]), zip(map(int, x.split('.')), mask_l)))})\n",
    "        return ret\n",
    "    except:\n",
    "        return dict([('prefix_%d' % x, None) for x in len_list])\n",
    "\n",
    "def derive_ip(x, **kwargs):\n",
    "    \"\"\" 衍生ip城市和运营商 \"\"\"\n",
    "    if not x:\n",
    "        return {'city':None, 'carrier':None}\n",
    "    else:\n",
    "        path = kwargs.get('path')\n",
    "        deriveip = IPSeeker.DeriveIp(path)\n",
    "        try:\n",
    "            city, carrier = deriveip.derive(x)\n",
    "            return {'city':city, 'carrier':carrier}\n",
    "        except:\n",
    "            return {'city':None, 'carrier':None}\n",
    "        \n",
    "    \n",
    "def derive_ua(x, **kwargs):\n",
    "    \"\"\" 衍生ua \"\"\"\n",
    "    if not x:\n",
    "        return {\"device_family\": None, \n",
    "                \"os_family\": None,\n",
    "                \"ua_family\": None}\n",
    "    else:\n",
    "        ua_dict = user_agent_parser.Parse(x)\n",
    "        return {\"device_family\": ua_dict['device']['family'], \n",
    "                \"os_family\": ua_dict['os']['family'],\n",
    "                \"ua_family\": ua_dict['user_agent']['family']}\n",
    "    \n",
    "def df_derive(df, col, derive_func, **kwargs):\n",
    "    \"\"\"\n",
    "    从spark dataframe的一列衍生出多列\n",
    "    \"\"\"\n",
    "    derive_cols = sorted(derive_func(None,  **kwargs).keys())\n",
    "    def udf_derive(derive_func, **kwargs):\n",
    "        def f(x):\n",
    "            derive_ret = derive_func(x, **kwargs)\n",
    "            return u'\\u0001'.join([\"%s\" % derive_ret[x] for x in derive_cols])\n",
    "        return functions.udf(f, StringType())\n",
    "    df_new = df.withColumn('derive', udf_derive(derive_func, **kwargs)(col)\n",
    "                           ).withColumn(\"splitcol\" ,functions.split(functions.col(\"derive\"), u\"\\u0001\")\n",
    "                                        )\n",
    "    for i ,c in enumerate(derive_cols):\n",
    "        df_new = df_new.withColumn( col + '_' +c, functions.col(\"splitcol\").getItem(i))\n",
    "    df_new = df_new.drop('splitcol')\n",
    "    df_new = df_new.drop('derive')\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau, describe\n",
    "import math\n",
    "import bisect\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 统计函数\n",
    "\n",
    "common_default_value = -1e8  # 数值型特征的默认值\n",
    "\n",
    "def category_stats(event_list, schema, **args):\n",
    "    \"\"\" \n",
    "    类别和离散类字段的统计特征\n",
    "    \"\"\"\n",
    "    feature_col = args['col']\n",
    "    if not event_list:\n",
    "        return cat_stat([], feature_col, **args)\n",
    "    feature_col_idx = schema.index(feature_col)\n",
    "    values = [x[feature_col_idx] for x in event_list if x[feature_col_idx]]  # 注意：这里过滤掉了''\n",
    "\n",
    "    return cat_stat(values, feature_col)\n",
    "\n",
    "def number_stats(event_list, schema, **args):\n",
    "    \"\"\" \n",
    "    连续数值的统计特征\n",
    "    \"\"\"\n",
    "    feature_col = args['col']\n",
    "    if not event_list:\n",
    "        return num_stat([], feature_col)\n",
    "    feature_col_idx = schema.index(feature_col)\n",
    "    values = [float(x[feature_col_idx]) for x in event_list if x[feature_col_idx]]  # 注意：这里过滤掉了''\n",
    "\n",
    "    return num_stat(values, feature_col)\n",
    "\n",
    "def num_stat(ls, feature_name=None):\n",
    "    \"\"\"\n",
    "    数值型字段的统计特征\n",
    "\n",
    "    :param feature_name: string, 特征名称前缀\n",
    "    :param ls: list, 被统计的向量\n",
    "    :param args type: simple or all, simple表示只计算简单统计量  all表示计算全部统计量\n",
    "    :return: a dict of statistic parameter and value, e.g. {'feature1_avg.num':1.00,'feature1_std':0.23}\n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    ret['Avg'] = common_default_value\n",
    "    ret['Std'] = common_default_value\n",
    "    ret['Max'] = common_default_value\n",
    "    ret['Min'] = common_default_value\n",
    "    ret['Sum'] = common_default_value\n",
    "    for i in [10, 25, 50, 75, 90]:\n",
    "        ret['Quar%s' % i] = common_default_value\n",
    "    ret['Ptp'] = common_default_value  # 极差 max-min\n",
    "    ret['Cv'] = common_default_value  # 变异系数\n",
    "    ret['Skew'] = common_default_value  # 偏度 偏度可能有正负 取值无界\n",
    "    ret['Kur'] = common_default_value  # 峰度\n",
    "    ret['MeanAbsDev'] = common_default_value  # 平均绝对离差\n",
    "    ret['Iqr'] = common_default_value\n",
    "\n",
    "    if ls:\n",
    "        arr = np.array(ls)\n",
    "        desc = describe(arr)\n",
    "        cnt = desc.nobs\n",
    "        ret['Avg'] = desc.mean\n",
    "        if not math.isnan(desc.variance):\n",
    "            ret['Std'] = np.sqrt(desc.variance)\n",
    "        ret['Max'] = desc.minmax[1]\n",
    "        ret['Min'] = desc.minmax[0]\n",
    "        ret['Ptp'] = ret['Max'] - ret['Min']\n",
    "        ret['Sum'] = desc.mean * cnt\n",
    "        ret['Cv'] = 1.0 * ret['Std'] / (np.abs(ret['Avg']) + 1e-8)\n",
    "        ret['Skew'] = desc.skewness\n",
    "        ret['Kur'] = desc.kurtosis\n",
    "        ret['MeanAbsDev'] = np.abs(arr - desc.mean).sum() / cnt\n",
    "        perc = [10, 25, 50, 75, 90]\n",
    "        perc_values = np.percentile(arr, perc)\n",
    "        for i, p in enumerate(perc):\n",
    "            ret['Quar%s' % p] = perc_values[i]\n",
    "        ret['Iqr'] = ret['Quar%s' % 75] - ret['Quar%s' % 25]\n",
    "\n",
    "    if feature_name:\n",
    "        return dict([('%s_%s' % (feature_name, i), float('%.5f' % j)) for i, j in ret.items()])\n",
    "\n",
    "    return  dict([(i,float('%.5f' % j))for i, j in ret.items()])\n",
    "\n",
    "\n",
    "def cat_stat(ls, feature_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    类别型字段的统计特征\n",
    "    \n",
    "    :param feature_name: string, 特征前缀 \n",
    "    :param ls: list, 被统计的向量\n",
    "    :param kwargs: no_set: Bool, 是否去掉类别特征  Tips:对于id类字段，建议设为True\n",
    "                   no_mode: Bool, 是否去掉众数特征  Tips: 如果no_set和no_mode都设为True，将删掉所有类别型特征\n",
    "    :return: dict，特征名:特征值\n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    # if not kwargs.get('no_set', False):\n",
    "    #     ret['catstat_Set'] = []\n",
    "    # if not kwargs.get('no_mode', False):\n",
    "    #     ret['catstat_Mode'] = []\n",
    "    ret['catstat_Cnt'] = -1\n",
    "    ret['catstat_Entropy'] = -1\n",
    "    ret['catstat_Gini'] = -1\n",
    "    ret.update(num_stat([], 'catstat'))\n",
    "\n",
    "    if ls:\n",
    "        value_set, value_cnt, most_common_values, histo = counter(ls)\n",
    "        histo_values = histo.values()\n",
    "        # if not kwargs.get('no_set', False):\n",
    "        #     ret['catstat_Set'] = list(value_set)\n",
    "        # if not kwargs.get('no_mode', False):\n",
    "        #     ret['catstat_Mode'] = list(most_common_values)\n",
    "        ret['catstat_Cnt'] = value_cnt\n",
    "        ret['catstat_Entropy'] = get_entropy(histo_values)\n",
    "        ret['catstat_Gini'] = get_gini(histo_values)\n",
    "        ret.update(num_stat(histo_values, 'catstat'))\n",
    "\n",
    "    if feature_name:\n",
    "        return dict([('%s_%s' % (feature_name, i),j) for i,j in ret.items()])\n",
    "\n",
    "    return ret\n",
    "\n",
    "def counter(arr):\n",
    "    \"\"\"\n",
    "    计算数组的histogram mode count 等\n",
    "    \n",
    "    :param arr: 数组\n",
    "    :return:  value_set: 不同的取值  value_cnt:不同的取值个数  most_common_values: 众数  histo:频数分布\n",
    "    \"\"\"\n",
    "    value_set = set()\n",
    "    most_common_values = set()\n",
    "    value_cnt = -1\n",
    "    histo = dict()  # 条形图\n",
    "    if not arr:\n",
    "        return value_set, value_cnt, most_common_values, histo\n",
    "\n",
    "    cnt_values_map = dict()  # 次数到值set的字典 为了一次遍历就得到众数的set\n",
    "    cnt_values_map[0] = set(arr)  # 初始化\n",
    "    most_commnt_cnt = 0  # 众数出现的次数\n",
    "    for a in arr:\n",
    "        value_set.add(a)\n",
    "        if not a in histo:\n",
    "            histo[a] = 1\n",
    "        else:\n",
    "            histo[a] = histo[a] + 1\n",
    "        if not histo[a] in cnt_values_map:\n",
    "            cnt_values_map[histo[a]] = set()\n",
    "            cnt_values_map[histo[a]].add(a)\n",
    "        else:\n",
    "            cnt_values_map[histo[a]].add(a)\n",
    "        if histo[a] > most_commnt_cnt:\n",
    "            most_commnt_cnt = histo[a]\n",
    "    most_common_values = cnt_values_map[most_commnt_cnt]\n",
    "    value_cnt = len(value_set)\n",
    "    return value_set, value_cnt, most_common_values, histo\n",
    "\n",
    "\n",
    "def get_entropy(nums):\n",
    "    \"\"\"\n",
    "    计算信息熵\n",
    "    \n",
    "    Tips: 当负数和正数混合在一起时，total可能是负数，math.log 会报错 math domain error，\n",
    "    对于包含负数的序列，无法直接计算熵，返回-1\n",
    "    \"\"\"\n",
    "\n",
    "    if not nums:\n",
    "        return common_default_value\n",
    "    entro = 0.0\n",
    "    total = sum(nums)\n",
    "    if total <= 0.0:\n",
    "        return common_default_value\n",
    "    for num in nums:\n",
    "        p = 1.0 * num / total\n",
    "        if p > 1e-5:\n",
    "            entro += p * math.log(p)\n",
    "    if entro != 0.0:\n",
    "        entro = -entro\n",
    "    return float('%.5f' % entro)\n",
    "\n",
    "\n",
    "def get_gini(counts):\n",
    "    \"\"\" \n",
    "    计算gini不纯度\n",
    "    \"\"\"\n",
    "    if not counts:\n",
    "        return common_default_value\n",
    "    gini = 0.0\n",
    "    counts_sum = sum(counts)\n",
    "    for i in counts:\n",
    "        gini += (1.0 * i / counts_sum) ** 2\n",
    "    gini = 1 - gini\n",
    "\n",
    "    return float('%.5f' % gini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 时间特征\n",
    "def get_time_delta_list(time_list, attr_name='second'):\n",
    "    \"\"\" \n",
    "    计算时间序列的差值序列\n",
    "    \"\"\"\n",
    "    deltas = []\n",
    "    for i, j in enumerate(time_list):\n",
    "        if i:\n",
    "            deltas.append((j - time_list[i - 1]))\n",
    "    if attr_name == 'second':\n",
    "        return deltas\n",
    "    elif attr_name == 'minute':\n",
    "        return [1.0 * i / 60 for i in deltas]\n",
    "    elif attr_name == 'hour':\n",
    "        return [1.0 * i / 60 / 60 for i in deltas]\n",
    "    elif attr_name == 'day':\n",
    "        return [1.0 * i / 60 / 60 / 24 for i in deltas]\n",
    "    return deltas\n",
    "\n",
    "def timedelta_stat(event_list, schema, **args):\n",
    "    \"\"\"\n",
    "    计算序列的时间间隔，再对时间间隔序列做数值统计\n",
    "    \"\"\"\n",
    "    col_timestamp = args.get('col')  # mktime 转换后的float型时间戳\n",
    "    ind_timestamp = schema.index(col_timestamp)\n",
    "    unit = args.get('unit', 'second')\n",
    "    return num_stat(get_time_delta_list([x[ind_timestamp] for x in event_list], unit), \n",
    "                    'timedelta_stat_unit_%s' % unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 类别特征\n",
    "def cat_set_feature(events, schema, **args):\n",
    "    \"\"\"\n",
    "    类别型特征的取值直接作为特征\n",
    "    \"\"\"\n",
    "    feature_col = args['col']\n",
    "    if not events:\n",
    "        return {\"set_feature_%s\" % feature_col: []}\n",
    "    ind_col = schema.index(feature_col)\n",
    "    return {\"set_feature_%s\" % feature_col: list(set([x[ind_col] for x in events]))}\n",
    "\n",
    "def cat_mode_feature(events, schema, **args):\n",
    "    \"\"\"\n",
    "    类别字段的众数特征\n",
    "\n",
    "    注意：我们假定events是按照时间先后顺序排序好的，如果众数有多个，取最后出现的一个\n",
    "    \"\"\"\n",
    "    feature_col = args['col']\n",
    "    if not events:\n",
    "        return {\"mode_feature_%s\" % feature_col: None}\n",
    "    ind_col = schema.index(feature_col)\n",
    "    mode_values = pd.Series([e[ind_col] for e in events]).mode().tolist()\n",
    "    if len(mode_values)==1:\n",
    "        return {\"mode_feature_%s\" % feature_col: mode_values[0]}\n",
    "    else:\n",
    "        mode_values_set = set(mode_values)\n",
    "        for e in reversed(events):\n",
    "            if e[ind_col] in mode_values_set:\n",
    "                return {\"mode_feature_%s\" % feature_col: e[ind_col]}\n",
    "    return {\"mode_feature_%s\" % feature_col: \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 其他函数\n",
    "def add_prefix_on_dict(d, prefix, delim='_'):\n",
    "    \"\"\" \n",
    "    给dict 的每个key 加前缀\n",
    "    \"\"\"\n",
    "    return dict([(\"%s%s%s\" % (prefix, delim, i), j) for i,j in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 评估函数\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "class ClassificationEvaluate():\n",
    "    \"\"\"\n",
    "    分类模型的评估指标\n",
    "    \"\"\"\n",
    "    \n",
    "    def precision_recall(self, y_trues, scores):\n",
    "        assert len(y_trues)==len(scores)\n",
    "        precision, recall, _ = precision_recall_curve(y_trues, scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post', label='AUC = %0.5f' % pr_auc)\n",
    "        plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()\n",
    "        \n",
    "    def roc(self, y_trues, scores):\n",
    "        assert len(y_trues)==len(scores)\n",
    "        fpr, tpr, _ = roc_curve(y_trues, scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='AUC = %0.5f' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
